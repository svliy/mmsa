{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import get_config_regression\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_config_regression('dmd', 'mosei', '/workspace/projects/mmsa/config/config_regression.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.featurePath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集的label\n",
    "# train_labels = data['train']['regression_labels']\n",
    "# val_labels = data['valid']['regression_labels']\n",
    "# test_labels = data['test']['regression_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels.shape, val_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label_arr(labels):\n",
    "#     label_arr = np.zeros(7, dtype=np.int64)\n",
    "\n",
    "#     for key in labels:\n",
    "#         label_arr[int(np.round(key)) + 3] += 1\n",
    "\n",
    "#     print(label_arr, f\"sum:{sum(label_arr)}\")\n",
    "#     return label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_label_arr(train_labels)\n",
    "# get_label_arr(val_labels)\n",
    "# get_label_arr(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_label_arr(train_labels) + get_label_arr(val_labels) + get_label_arr(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['text'].shape, data['train']['vision'].shape, data['train']['vision'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 35\n",
    "data['test']['raw_text'][id], data['test']['regression_labels'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['raw_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测 id 和 raw-text 是否对应\n",
    "index = 0\n",
    "for id in data['train']['id']:\n",
    "    if id == '7ZzbemE4QEE$_$27':\n",
    "        break\n",
    "    index += 1\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['raw_text'][index], data['train']['regression_labels'][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化单个模态的字典激活分布区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_att_weight = np.load('/workspace/projects/mmsa/visualization/l_att_weight_list.npy', allow_pickle=True)\n",
    "v_att_weight = np.load('/workspace/projects/mmsa/visualization/v_att_weight_list.npy', allow_pickle=True)\n",
    "a_att_weight = np.load('/workspace/projects/mmsa/visualization/a_att_weight_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(att_weight):\n",
    "    tmp = []\n",
    "    for x in att_weight:\n",
    "        tmp.append(x.tolist()[0])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tmp, v_tmp, a_tmp = get_data(l_att_weight), get_data(v_att_weight), get_data(a_att_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element_counts(arr):\n",
    "    from collections import Counter\n",
    "\n",
    "    # 将二维数组转换成一维数组\n",
    "    flat_arr = [item for sublist in arr for item in sublist]\n",
    "\n",
    "    # 使用 Counter 统计元素出现的次数\n",
    "    element_counts = Counter(flat_arr)\n",
    "\n",
    "    # 打印统计结果\n",
    "    # print(\"元素出现的次数：\", element_counts)\n",
    "    return element_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_element_counts = get_element_counts(l_tmp)\n",
    "# v_element_counts = get_element_counts(v_tmp)\n",
    "# a_element_counts = get_element_counts(a_tmp)\n",
    "\n",
    "# pos_element_counts = get_element_counts(pos_tmp)\n",
    "# neg_element_counts = get_element_counts(neg_tmp)\n",
    "\n",
    "# lva_element_counts = get_element_counts(lva_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历 Counter 对象的键值对\n",
    "# for token, count in lva_element_counts.items():\n",
    "#     print(f\"Token: {token}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # 过滤掉元素 0\n",
    "# l_filtered_element_counts = {element: count for element, count in l_element_counts.items() if element != 0}\n",
    "\n",
    "# # 提取过滤后的元素和出现次数\n",
    "# l_elements = list(l_filtered_element_counts.keys())\n",
    "# l_counts = list(l_filtered_element_counts.values())\n",
    "\n",
    "# # same for vision\n",
    "# v_filtered_element_counts = {element: count for element, count in v_element_counts.items() if element != 0}\n",
    "# v_elements = list(v_filtered_element_counts.keys())\n",
    "# v_counts = list(v_filtered_element_counts.values())\n",
    "\n",
    "# # same for audio\n",
    "# a_filtered_element_counts = {element: count for element, count in a_element_counts.items() if element != 0}\n",
    "# a_elements = list(a_filtered_element_counts.keys())\n",
    "# a_counts = list(a_filtered_element_counts.values())\n",
    "\n",
    "# # same for pos\n",
    "# pos_filtered_element_counts = {element: count for element, count in pos_element_counts.items() if element != 0}\n",
    "# pos_elements = list(pos_filtered_element_counts.keys())\n",
    "# pos_counts = list(pos_filtered_element_counts.values())\n",
    "\n",
    "# same for neg\n",
    "# neg_filtered_element_counts = {element: count for element, count in neg_element_counts.items() if element != 0}\n",
    "# neg_elements = list(neg_filtered_element_counts.keys())\n",
    "# neg_counts = list(neg_filtered_element_counts.values())\n",
    "\n",
    "# 绘制直方图，设置小长方形边缘颜色为蓝色\n",
    "# plt.bar(pos_elements, pos_counts, edgecolor='blue')\n",
    "# plt.bar(neg_elements, neg_counts, edgecolor='blue')\n",
    "\n",
    "\n",
    "# # 添加标题和标签（转换为英文）\n",
    "# plt.title('Histogram of Element Occurrences (Excluding Element 0)')\n",
    "# plt.xlabel('Element')\n",
    "# plt.ylabel('Occurrences')\n",
    "\n",
    "# # 显示图形\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(l_elements), len(v_elements), len(a_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字典 `token` 在迭代过程中的变化情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_index = 1 # 设置 epoch (1-?)\n",
    "token_index = 0 # 设置 字典token (0-511)\n",
    "\n",
    "# train_folder = 'May12_00-59-04_ea6f534ea7b8mosei'\n",
    "# train_folder = 'May13_21-58-40_ea6f534ea7b8mosei'\n",
    "train_folder = 'May14_06-23-11_ea6f534ea7b8mosei'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单个 `epoch` 内字典 `token` 的变化过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个字典 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "dict_table = np.load(f'/workspace/projects/mmsa/visualization/{train_folder}/dict_table_{epoch_index}.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 维度信息分别表示：迭代次数，字典大小，字典token的维度大小\n",
    "print(f\"The shape of dict_table is: {dict_table.shape}\")\n",
    "print(f\"The type of dict_table is: {type(dict_table)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dict_table, axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table = np.sum(dict_table, axis=2) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置中文字体\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(dict_table.T, cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel('Number of Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多个 epoch 内字典 `token` 的变化情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 1 # 设置 epoch (1-?)\n",
    "epoch_end = 31 # 设置 字典token (0-511)\n",
    "\n",
    "# train_folder = 'May12_00-59-04_ea6f534ea7b8mosei'\n",
    "# train_folder = 'May13_21-58-40_ea6f534ea7b8mosei'\n",
    "train_folder = 'May14_06-23-11_ea6f534ea7b8mosei'\n",
    "\n",
    "dict_table_all = np.load(f'/workspace/projects/mmsa/visualization/{train_folder}/dict_table_{epoch_start}.npy', allow_pickle=True)[:, :, :]\n",
    "\n",
    "for index in range(2, epoch_end + 1):\n",
    "    dict_table_tmp = np.load(f'/workspace/projects/mmsa/visualization/{train_folder}/dict_table_{index}.npy', allow_pickle=True)\n",
    "    # print(dict_table_tmp[:, 0, :].shape)\n",
    "    # print(dict_table_all[:, 0, :].shape)\n",
    "    dict_table_all = np.concatenate((dict_table_all, dict_table_tmp[:, :, :]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_all = np.sum(dict_table_all, axis=2) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每10次迭代更新1次\n",
    "dict_table_all = dict_table_all[::10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_all = dict_table_all.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dict_table_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to csv file\n",
    "df = pd.DataFrame(dict_table_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'/workspace/projects/mmsa/visualization/{train_folder}/dict_by_iter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置中文字体\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(dict_table_all.T, cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel('Number of Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看相同类别下三种模态的激活的公共字典 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练文件名\n",
    "train_name = 'May12_00-59-04_ea6f534ea7b8mosei'\n",
    "# train_name = 'May13_21-58-40_ea6f534ea7b8mosei'\n",
    "# train_name = 'May14_06-23-11_ea6f534ea7b8mosei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签\n",
    "train_labels = np.load(f'/workspace/projects/mmsa/visualization/{train_name}/label_list.npy', allow_pickle=True)\n",
    "# id\n",
    "id_list = np.load(f'/workspace/projects/mmsa/visualization/{train_name}/ids_list.npy', allow_pickle=True)\n",
    "# 原始文本\n",
    "raw_text_list = np.load(f'/workspace/projects/mmsa/visualization/{train_name}/raw_text_list.npy', allow_pickle=True)\n",
    "# 三种模态激活的字典token\n",
    "lva_att_weight_train = np.load(f'/workspace/projects/mmsa/visualization/{train_name}/lva_att_weight_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成1维数组\n",
    "train_labels = np.concatenate(train_labels, axis=0)[:,0]\n",
    "id_list = np.concatenate(id_list, axis=0)\n",
    "raw_text_list = np.concatenate(raw_text_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总的训练集样本数量\n",
    "train_labels.shape, id_list.shape, raw_text_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 转换\n",
    "print(\"转换前：\", train_labels)\n",
    "train_labels = np.round(train_labels)\n",
    "print(\"转换后：\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lva_att_weight_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个元素表示一个batch的数据，0-15表示语言模态的数据，16-31表示视觉模态的数据，32-47表示音频模态的数据\n",
    "lva_att_weight_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一个不是18\n",
    "lva_att_weight_train[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 lva_att_weight_train 获取三种模态的数据\n",
    "l_att_weight = []\n",
    "v_att_weight = []\n",
    "a_att_weight = []\n",
    "\n",
    "for lva_att_weight in lva_att_weight_train:\n",
    "    num = len(lva_att_weight) // 3\n",
    "    l_att_weight.append(lva_att_weight[: num])\n",
    "    v_att_weight.append(lva_att_weight[num : 2*num])\n",
    "    a_att_weight.append(lva_att_weight[2*num :])\n",
    "    \n",
    "\n",
    "l_att_weight = np.concatenate(l_att_weight)\n",
    "v_att_weight = np.concatenate(v_att_weight)\n",
    "a_att_weight = np.concatenate(a_att_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_att_weight.shape, v_att_weight.shape, a_att_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据为第 1 维为 16326 数组，方便后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 分类\n",
    "class_1 = [] # -3\n",
    "class_2 = []\n",
    "class_3 = []\n",
    "class_4 = []\n",
    "class_5 = []\n",
    "class_6 = []\n",
    "class_7 = []\n",
    "\n",
    "# 2 分类\n",
    "class_pos = []\n",
    "class_neg = []\n",
    "class_zero = []\n",
    "\n",
    "# 单分类\n",
    "class_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_l, data_v, data_a, label, id, raw_text in zip(l_att_weight, v_att_weight, a_att_weight, train_labels, id_list, raw_text_list):\n",
    "    # print(data_l.shape, data_v.shape, data_a.shape, label)\n",
    "    data_all = [data_l, data_v, data_a, label, id, raw_text]\n",
    "    class_all.append(data_all)\n",
    "    if label == -3:\n",
    "        class_1.append(data_all)\n",
    "    elif label == -2:\n",
    "        class_2.append(data_all)\n",
    "    elif label == -1:\n",
    "        class_3.append(data_all)\n",
    "    elif label == 0:\n",
    "        class_4.append(data_all)\n",
    "    elif label == 1:\n",
    "        class_5.append(data_all)\n",
    "    elif label == 2:\n",
    "        class_6.append(data_all)\n",
    "    elif label == 3:\n",
    "        class_7.append(data_all)\n",
    "    \n",
    "    if label > 0:\n",
    "        class_pos.append(data_all)\n",
    "    elif label == 0:\n",
    "        class_zero.append(data_all)\n",
    "    elif label < 0:\n",
    "        class_neg.append(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 分类\n",
    "len(class_1), len(class_2), len(class_3), len(class_4), len(class_5), len(class_6), len(class_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 分类\n",
    "len(class_pos), len(class_zero), len(class_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个类被\n",
    "len(class_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_sample(class_name, num):\n",
    "    \n",
    "    data_l, data_v, data_a, data_label, id, raw_text = class_name[num]\n",
    "    # 查看标签\n",
    "    # print(f\"标签：{pos_label}\")\n",
    "    # # 查看语言模态 L 激活的字典token\n",
    "    # print(f\"语言模态({len(np.nonzero(pos_l)[0])}):\",np.nonzero(pos_l)[0])\n",
    "    # # 查看视觉模态 V 激活的字典token\n",
    "    # print(f\"视觉模态({len(np.nonzero(pos_v)[0])}):\",np.nonzero(pos_v)[0])\n",
    "    # # 查看音频模态 A 激活的字典token\n",
    "    # print(f\"音频模态({len(np.nonzero(pos_a)[0])}):\",np.nonzero(pos_a)[0])\n",
    "    # 查看3个模态的激活的公共字典token\n",
    "    print(f\"ID：{id}; 标签：{data_label}; 文本：{raw_text}\")\n",
    "    intersection = np.intersect1d(np.nonzero(data_l)[0], np.nonzero(data_v)[0])\n",
    "    intersection = np.intersect1d(intersection, np.nonzero(data_a)[0])\n",
    "    print(f\"公共相应模态({len(intersection)}):\",intersection + 1) # 处理下标为 0 的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection + 1的愿意\n",
    "np.nonzero(np.array([1, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择 1 个样本\n",
    "# random_select_sample(class_pos, 200)\n",
    "# random_select_sample(class_zero, 2000) \n",
    "random_select_sample(class_1, 200) # 2056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 1 个类别下所有样本的三个模态激活的字典token\n",
    "for num in range(len(class_7)):\n",
    "    print(f\"第{num}个样本：\")\n",
    "    random_select_sample(class_7, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计不同类别激活的字典分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_table(class_tmp):\n",
    "    data_table = np.zeros((5, 512))\n",
    "\n",
    "    for data in class_tmp:\n",
    "        data_l, data_v, data_a, label, _, _ =  data\n",
    "        \n",
    "        data_l_nonzero_indices = np.nonzero(data_l)[0]\n",
    "        data_v_nonzero_indices = np.nonzero(data_v)[0]\n",
    "        data_a_nonzero_indices = np.nonzero(data_a)[0]\n",
    "\n",
    "        intersection = np.intersect1d(data_l_nonzero_indices, data_v_nonzero_indices)\n",
    "        intersection = np.intersect1d(intersection, data_a_nonzero_indices)\n",
    "\n",
    "        # union = np.union1d(data_l_nonzero_indices, data_v_nonzero_indices)\n",
    "        # union = np.union1d(union, data_a_nonzero_indices)\n",
    "\n",
    "        for x in data_l_nonzero_indices:\n",
    "            data_table[0][x] += 1\n",
    "            data_table[4][x] += 1\n",
    "        for x in data_v_nonzero_indices:\n",
    "            data_table[1][x] += 1\n",
    "            data_table[4][x] += 1\n",
    "        for x in data_a_nonzero_indices:\n",
    "            data_table[2][x] += 1\n",
    "            data_table[4][x] += 1\n",
    "        for x in intersection:\n",
    "            data_table[3][x] += 1\n",
    "        # for x in union:\n",
    "        #     data_table[4][x] += 1\n",
    "\n",
    "    return data_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_1 = get_data_table(class_1)\n",
    "data_table_2 = get_data_table(class_2)\n",
    "data_table_3 = get_data_table(class_3)\n",
    "data_table_4 = get_data_table(class_4)\n",
    "data_table_5 = get_data_table(class_5)\n",
    "data_table_6 = get_data_table(class_6)\n",
    "data_table_7 = get_data_table(class_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_pos = get_data_table(class_pos)\n",
    "data_table_zero = get_data_table(class_zero)\n",
    "data_table_neg = get_data_table(class_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_all = get_data_table(class_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l_non0_index = np.nonzero(data_table_all[0])[0]\n",
    "data_v_non0_index = np.nonzero(data_table_all[1])[0]\n",
    "data_a_non0_index = np.nonzero(data_table_all[2])[0]\n",
    "data_lva_non0_index = np.nonzero(data_table_all[4])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l_non0_index.shape, data_v_non0_index.shape, data_a_non0_index.shape, data_lva_non0_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.union1d(data_l_non0_index, data_v_non0_index)\n",
    "x = np.union1d(x, data_a_non0_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lva_non0_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 自定义颜色条范围\n",
    "# vmin = 0  # 最小值\n",
    "# vmax = 320  # 最大值\n",
    "\n",
    "# sns.heatmap(common, cmap=\"viridis\", yticklabels=['Language', 'Vision', 'Audio', 'Common'])\n",
    "\n",
    "sns.heatmap(data_table_all, cmap=\"viridis\")\n",
    "\n",
    "# plt.xticks(fontsize=5)\n",
    "plt.xlabel('Token Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择激活次数最多的前50个token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activate_token(data):\n",
    "    for idx in range(4):\n",
    "        print(np.nonzero(data[idx])[0])\n",
    "        print(f\"激活字典token数量: {len(np.nonzero(data[idx])[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取类别下三种模态激活的字典token分布\n",
    "get_activate_token(data_table_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_max(arr, k=50):\n",
    "    # 一个示例的一维numpy数组\n",
    "    # arr = np.array([10, 5, 8, 20, 3, 15])\n",
    "\n",
    "    # 获取前k个最大值的下标\n",
    "    top_k_indices = np.argsort(-arr)[:k]\n",
    "\n",
    "    # print(\"前\", k, \"个最大值的下标:\", end=\"\")\n",
    "    return top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the top_k function\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "top_k_max(x, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lva_topk_all = top_k_max(data_table_all[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lva_topk_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_all[4][lva_topk_all].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_all = data_table_all[0][lva_topk_all].astype(int)\n",
    "l_all = l_all[np.newaxis,:]\n",
    "\n",
    "v_all = data_table_all[1][lva_topk_all].astype(int)\n",
    "v_all = v_all[np.newaxis,:]\n",
    "\n",
    "a_all = data_table_all[2][lva_topk_all].astype(int)\n",
    "a_all = a_all[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lva_all = np.concatenate((l_all, v_all, a_all), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_all(index):\n",
    "    l_class_1 = data_table_1[index][lva_topk_all].astype(int)\n",
    "    l_class_1 = l_class_1[np.newaxis,:]\n",
    "\n",
    "    l_class_2 = data_table_2[index][lva_topk_all].astype(int)\n",
    "    l_class_2 = l_class_2[np.newaxis,:]\n",
    "\n",
    "    l_class_3 = data_table_3[index][lva_topk_all].astype(int)\n",
    "    l_class_3 = l_class_3[np.newaxis,:]\n",
    "\n",
    "    l_class_4 = data_table_4[index][lva_topk_all].astype(int)\n",
    "    l_class_4 = l_class_4[np.newaxis,:]\n",
    "\n",
    "    l_class_5 = data_table_5[index][lva_topk_all].astype(int)\n",
    "    l_class_5 = l_class_5[np.newaxis,:]\n",
    "\n",
    "    l_class_6 = data_table_6[index][lva_topk_all].astype(int)\n",
    "    l_class_6 = l_class_6[np.newaxis,:]\n",
    "\n",
    "    l_class_7 = data_table_7[index][lva_topk_all].astype(int)\n",
    "    l_class_7 = l_class_7[np.newaxis,:]\n",
    "\n",
    "    l_all = np.concatenate((l_class_7, l_class_6, l_class_5, l_class_4, l_class_3, l_class_2, l_class_1), axis=0)\n",
    "    return l_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_all = get_m_all(0)\n",
    "v_all = get_m_all(1)\n",
    "a_all = get_m_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lva_all = np.concatenate((l_all, v_all, a_all), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "# 自定义颜色条范围\n",
    "vmin = 0  # 最小值\n",
    "vmax = 7000  # 最大值\n",
    "\n",
    "# sns.heatmap(common, cmap=\"viridis\", yticklabels=['Language', 'Vision', 'Audio', 'Common'])\n",
    "plt.subplot(311) # 第一个画板的第一个子图\n",
    "ax1 = sns.heatmap(l_all, cmap=\"viridis\",square=True,\n",
    "                xticklabels=lva_topk_all,\n",
    "                yticklabels=['+3', '+2', '+1', '0', '-1', '-2', '-3'],\n",
    "                vmax=vmax, vmin=vmin,\n",
    "                cbar=False)\n",
    "\n",
    "ax1.xaxis.tick_bottom()\n",
    "ax1.yaxis.tick_left()\n",
    "ax1.title.set_text('Language Modality')\n",
    "\n",
    "plt.subplot(312) # 第一个画板的第二个子图\n",
    "\n",
    "# 自定义颜色条范围\n",
    "vmin = 0  # 最小值\n",
    "vmax = 7000  # 最大值\n",
    "\n",
    "# sns.heatmap(common, cmap=\"viridis\", yticklabels=['Language', 'Vision', 'Audio', 'Common'])\n",
    "\n",
    "ax1 = sns.heatmap(v_all, cmap=\"viridis\",square=True,\n",
    "                xticklabels=lva_topk_all,\n",
    "                yticklabels=['+3', '+2', '+1', '0', '-1', '-2', '-3'],\n",
    "                vmax=vmax, vmin=vmin,\n",
    "                cbar=False)\n",
    "\n",
    "ax1.xaxis.tick_bottom()\n",
    "ax1.yaxis.tick_left()\n",
    "ax1.title.set_text('Vision Modality')\n",
    "\n",
    "plt.subplot(313) # 第一个画板的第二个子图\n",
    "\n",
    "# 自定义颜色条范围\n",
    "vmin = 0  # 最小值\n",
    "vmax = 7000  # 最大值\n",
    "\n",
    "# sns.heatmap(common, cmap=\"viridis\", yticklabels=['Language', 'Vision', 'Audio', 'Common'])\n",
    "\n",
    "ax1 = sns.heatmap(a_all, cmap=\"viridis\",square=True,\n",
    "                xticklabels=lva_topk_all,\n",
    "                yticklabels=['+3', '+2', '+1', '0', '-1', '-2', '-3'],\n",
    "                vmax=vmax, vmin=vmin,\n",
    "                cbar=False)\n",
    "\n",
    "ax1.xaxis.tick_bottom()\n",
    "ax1.yaxis.tick_left()\n",
    "ax1.title.set_text('Acoustic Modality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_topk_pos = top_k_max(data_table_pos[0])\n",
    "v_topk_pos = top_k_max(data_table_pos[1])\n",
    "a_topk_pos = top_k_max(data_table_pos[2])\n",
    "c_topk_pos = top_k_max(data_table_pos[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_topk(data_table):\n",
    "    l_topk = top_k_max(data_table[0])\n",
    "    v_topk = top_k_max(data_table[1])\n",
    "    a_topk = top_k_max(data_table[2])\n",
    "    c_topk = top_k_max(data_table[3])\n",
    "    print(\"Language:\", l_topk)\n",
    "    print(\"Vision:\", v_topk)\n",
    "    print(\"Audio:\", a_topk)\n",
    "    print(\"Common:\", c_topk)\n",
    "    intersection = np.intersect1d(l_topk, v_topk)\n",
    "    intersection = np.intersect1d(intersection, a_topk)\n",
    "    print(\"Intersection:\", intersection)\n",
    "    print(\"Intersection:\", len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topk(data_table_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_by_modality(data_table):\n",
    "    l_topk = top_k_max(data_table[0])\n",
    "    v_topk = top_k_max(data_table[1])\n",
    "    a_topk = top_k_max(data_table[2])\n",
    "    union = np.union1d(l_topk, v_topk)\n",
    "    union = np.union1d(union, a_topk)\n",
    "    print(union, len(union))\n",
    "    print(data_table[0][union].astype(int))\n",
    "    print(data_table[1][union].astype(int))\n",
    "    print(data_table[2][union].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topk_by_modality(data_table_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_topk_neg = top_k_max(data_table_neg[0])\n",
    "v_topk_neg = top_k_max(data_table_neg[1])\n",
    "a_topk_neg = top_k_max(data_table_neg[2])\n",
    "c_topk_neg = top_k_max(data_table_neg[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_topk_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topk_by_modality(l_topk_neg, v_topk_neg, a_topk_neg, data_table_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_topk = l_topk_neg\n",
    "v_topk = v_topk_neg\n",
    "a_topk = a_topk_neg\n",
    "data_table = data_table_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = np.union1d(l_topk, v_topk)\n",
    "union = np.union1d(union, a_topk)\n",
    "union, len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[0][union].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[1][union].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[2][union].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[3][union].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersect(m1, m2):\n",
    "    m12 = np.intersect1d(m1, m2)\n",
    "    print(f\"m1 与 m2 的交集: {m12}\")\n",
    "    print(f\"The length: {len(m12)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_intersect(l_topk_pos, v_topk_pos)\n",
    "get_intersect(l_topk_pos, a_topk_pos)\n",
    "get_intersect(v_topk_pos, a_topk_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_intersect(l_topk_neg, v_topk_neg)\n",
    "get_intersect(l_topk_neg, a_topk_neg)\n",
    "get_intersect(v_topk_neg, a_topk_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_intersect(l_topk_pos, l_topk_neg)\n",
    "get_intersect(v_topk_pos, v_topk_neg)\n",
    "get_intersect(a_topk_pos, a_topk_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "\n",
    "# 自定义颜色条范围\n",
    "# vmin = 0  # 最小值\n",
    "# vmax = 320  # 最大值\n",
    "\n",
    "sns.heatmap(data_table_6[:4,:], cmap=\"viridis\",\n",
    "            yticklabels=['Language', 'Vision', 'Audio', 'Common'],\n",
    "            linewidths=0.5, linecolor='grey')\n",
    "\n",
    "# plt.xticks(fontsize=5)\n",
    "plt.xlabel('Token Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_view = data_table_7\n",
    "\n",
    "plt.figure(figsize=(24, 6))\n",
    "\n",
    "# 自定义颜色条范围\n",
    "vmin = 0  # 最小值\n",
    "vmax = 320  # 最大值\n",
    "\n",
    "sns.heatmap(data_view[:4], cmap=\"viridis\", xticklabels=unique_array, yticklabels=['Language', 'Vision', 'Audio', 'Common'],\n",
    "            linewidths=0.5, linecolor='grey')\n",
    "\n",
    "plt.xticks(fontsize=5)\n",
    "plt.xlabel('Token Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CosineEmbeddingLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(1, 3, 2)\n",
    "input2 = torch.randn(1, 3, 2)\n",
    "# create a tensor filled with -1\n",
    "target = torch.tensor([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7117, -1.2739],\n",
       "         [-0.0130, -0.5585],\n",
       "         [ 0.4072, -2.3323]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7728,  0.4600],\n",
       "         [-0.7673,  1.0882],\n",
       "         [-0.3782,  0.4005]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = loss(input1, input2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4294, 0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
