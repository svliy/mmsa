{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clip_fdt as fdt\n",
    "# from clip_fdt import Query_model, Clip_FDT, AllGather\n",
    "# from loss import ClipInfoCELoss\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mdir\u001b[39m(\u001b[43mfdt\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fdt' is not defined"
     ]
    }
   ],
   "source": [
    "dir(fdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 现状\n",
    "\n",
    "手里有模态的token，如何构建一个字典，将这些token重建，并进行对比学习？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sd_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16384\u001b[39m\n\u001b[1;32m      4\u001b[0m sd_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 5\u001b[0m space_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(sd_num, sd_dim)\n\u001b[1;32m      6\u001b[0m sd_temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;66;03m# Softmax温度系数\u001b[39;00m\n\u001b[1;32m      7\u001b[0m att_func_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsemax\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "# 字典\n",
    "sd_num = 16384\n",
    "sd_dim = 512\n",
    "space_dict = torch.randn(sd_num, sd_dim)\n",
    "sd_temperature = 2.0 # Softmax温度系数\n",
    "att_func_type = 'sparsemax'\n",
    "pool_type = 'max'\n",
    "raw_img_ft_dim = raw_txt_ft_dim = raw_acoustic_ft_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 解耦的同质特征 common feature \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# torch.Size([16, 50, 46]) torch.Size([16, 50, 925]) torch.Size([16, 50, 232])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# [batch_size, feature_dim, seq_len]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m com_language \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m46\u001b[39m)\n\u001b[1;32m      5\u001b[0m com_audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m925\u001b[39m)\n\u001b[1;32m      6\u001b[0m com_vision \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m232\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 解耦的同质特征 common feature \n",
    "# torch.Size([16, 50, 46]) torch.Size([16, 50, 925]) torch.Size([16, 50, 232])\n",
    "# [batch_size, feature_dim, seq_len]\n",
    "com_language = torch.randn(16, 50, 46)\n",
    "com_audio = torch.randn(16, 50, 925)\n",
    "com_vision = torch.randn(16, 50, 232)\n",
    "\n",
    "com_language = com_language.transpose(1, 2)\n",
    "com_audio = com_audio.transpose(1, 2)\n",
    "com_vision = com_vision.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query_model会做两件事：\n",
    "- 使用MLP将输入模态的特征维度 feature_dim 转为字典特征维度 sd_dim\n",
    "- 返回注意力权重，重构特征，字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_query_model = Query_model(ft_dim=raw_img_ft_dim,\n",
    "                              sd_dim=sd_dim,\n",
    "                              temperature=sd_temperature,\n",
    "                              att_func_type=att_func_type,\n",
    "                              pool_type=pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取图像的基于字典的重构特征\n",
    "att_weight, sd_img_ft, img_k = img_query_model(com_language, space_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(att_weight))\n",
    "print(type(sd_img_ft))\n",
    "# 字典\n",
    "print(type(img_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of att_weight: torch.Size([16, 16384])\n",
      "The shape of sd_img_ft: torch.Size([16, 512])\n",
      "The shape of img_k: torch.Size([16384, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of att_weight: {att_weight.shape}\")\n",
    "print(f\"The shape of sd_img_ft: {sd_img_ft.shape}\")\n",
    "print(f\"The shape of img_k: {img_k.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_img_ft[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_fdt = Clip_FDT(\n",
    "    image_encode=None,\n",
    "    text_encode=None,\n",
    "    use_allgather=None,\n",
    "    sd_num=sd_num,\n",
    "    sd_dim=sd_dim,\n",
    "    raw_img_ft_dim=raw_img_ft_dim,\n",
    "    raw_txt_ft_dim=raw_txt_ft_dim,\n",
    "    raw_acoustic_ft_dim=raw_acoustic_ft_dim,\n",
    "    att_func_type=att_func_type,\n",
    "    pool_type=pool_type,\n",
    "    sd_temperature=sd_temperature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clip_fdt(com_language, com_audio, com_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image_sd_LV, logits_per_text_sd_LV = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_per_image_sd_LV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_per_text_sd_LV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_loss = ClipInfoCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.8579, grad_fn=<DivBackward0>),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_loss(logits_per_image_sd_LV, logits_per_text_sd_LV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (3, 4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 2), \\\n",
    "(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sd_acoustic_ft, _ = clip_fdt.extract_acoustic_sd_ft(com_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_acoustic_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mmsa/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = []\n",
    "a = torch.rand(16, 1)\n",
    "b = torch.rand(16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.append(a)\n",
    "st.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(st).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
